{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d60b9017-e925-43a8-9fcf-0a10dc85cd21",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:6px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d980c9-9381-4a9d-9b01-0193774cbe65",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <h1>Empirical Asset Pricing with ML in Europe</h1>\n",
    "  <h3>HEC Liege</h3>\n",
    "  <h4><em>Lucas Dubois and Myriam Lamborelle</em></h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2f090-5619-4f94-9b1b-68334c01b3e4",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:6px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "b8aac131-10a4-494b-ba3b-de0eb430bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torch.optim as topt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statsmodels.stats import diagnostic\n",
    "from statsmodels.stats.sandwich_covariance import cov_hac\n",
    "from statsmodels.stats.sandwich_covariance import se_cov\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from stargazer.stargazer import Stargazer\n",
    "from linearmodels.panel import PanelOLS\n",
    "from linearmodels.panel import PooledOLS\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "7419437e-8507-4419-8a15-23210928733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/Users/lucasdubois/Desktop/LaTeX/EAP-ML/CODE/DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "eb8c4211-0c77-44b0-bed1-9befbd3c8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_path=\"/Users/lucasdubois/Desktop/LaTeX/EAP-ML/CODE/Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "c0015e4d-791f-4cbe-98dd-cbd6d6c061bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "offwhite = (230/255, 230/255, 220/255)\n",
    "midnight = (0/255, 22/255, 36/255)\n",
    "steelblue = (171/255, 193/255, 223/255)\n",
    "primaryred = (127/255, 20/255, 22/255)\n",
    "harmonizedblue =(48/255,88/255,140/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6854a20a-a8e3-472b-9a38-9e1d8f916679",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:4px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e54c6-c518-4a5e-a3e7-b3402f07233a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h2> <small>1</small>&nbsp;&nbsp;&nbsp;&nbsp;Database:</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6cdb78-d7c7-44f8-b13a-261edc7f1e3f",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c92ad-d690-45d9-9ce2-36a14a015154",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>1.1</small>&nbsp;&nbsp;&nbsp;&nbsp;Stocks:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "706f24cf-2f76-46e4-8b91-c51ce4d3721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(path + \"stoxx600.xlsx\")\n",
    "\n",
    "df.rename(columns={df.columns[0]: \"Date\"}, inplace=True)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "c48c9214-940b-407d-8d7c-e71aef535c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ~df.columns.str.startswith(\"#ERROR\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "c8f7fe04-1ae0-41e9-956c-9627c59ebdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df.melt(\n",
    "    id_vars=\"Date\",\n",
    "    var_name=\"col\",\n",
    "    value_name=\"value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "e788c0bb-3512-4dc6-83ab-30b3c1a52b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[[\"Stock\", \"Datatype\"]] = (\n",
    "    df_long[\"col\"]\n",
    "    .str.split(\" - \", n=1, expand=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "7cdee595-a89e-49ec-8a17-b375aa00f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel = (\n",
    "    df_long\n",
    "    .pivot_table(\n",
    "        index=[\"Date\", \"Stock\"],\n",
    "        columns=\"Datatype\",\n",
    "        values=\"value\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "cd5fbf2a-9e42-4dde-9cd3-d87c3a14c60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype       Date     Stock  DIVIDEND YIELD  MARKET VALUE  \\\n",
      "0        2005-01-01  3I GROUP            2.13       4085.77   \n",
      "435      2005-02-01  3I GROUP            2.00       4355.70   \n",
      "871      2005-03-01  3I GROUP            2.04       4279.01   \n",
      "1307     2005-04-01  3I GROUP            2.11       4134.96   \n",
      "1743     2005-05-01  3I GROUP            2.23       3913.99   \n",
      "\n",
      "Datatype  MRKT VALUE TO BOOK   PER  PRICE INDEX  TOT RETURN IND  \\\n",
      "0                       1.12  30.4        244.9          302.56   \n",
      "435                     1.20  32.4        261.0          322.55   \n",
      "871                     1.18  31.8        256.4          316.87   \n",
      "1307                    1.03  30.7        247.4          305.74   \n",
      "1743                    0.98  29.1        234.6          289.84   \n",
      "\n",
      "Datatype  TURNOVER BY VALUE  TURNOVER BY VOLUME  \n",
      "0                  340749.3             83500.9  \n",
      "435                338096.4             81321.8  \n",
      "871                446679.1            100759.9  \n",
      "1307               367390.2             85149.6  \n",
      "1743               341499.1             82397.3  \n",
      "Datatype       Date                   Stock  DIVIDEND YIELD  MARKET VALUE  \\\n",
      "130674   2025-08-01  ZURICH INSURANCE GROUP            5.03      81461.63   \n",
      "131272   2025-09-01  ZURICH INSURANCE GROUP            4.85      84564.38   \n",
      "131871   2025-10-01  ZURICH INSURANCE GROUP            4.91      83452.06   \n",
      "132470   2025-11-01  ZURICH INSURANCE GROUP            5.04      81256.69   \n",
      "133069   2025-12-01  ZURICH INSURANCE GROUP            4.85      84418.00   \n",
      "\n",
      "Datatype  MRKT VALUE TO BOOK   PER  PRICE INDEX  TOT RETURN IND  \\\n",
      "130674                  3.00  15.6       2140.6        12091.53   \n",
      "131272                  3.12  16.2       2222.2        12552.07   \n",
      "131871                  3.07  16.0       2192.9        12386.97   \n",
      "132470                  2.99  15.6       2135.3        12061.11   \n",
      "133069                  3.11  16.2       2218.3        12530.35   \n",
      "\n",
      "Datatype  TURNOVER BY VALUE  TURNOVER BY VOLUME  \n",
      "130674            2082217.0              3401.1  \n",
      "131272            2530846.0              3548.2  \n",
      "131871            2899719.0              3756.0  \n",
      "132470            2856944.0              3936.2  \n",
      "133069            2640802.0              3663.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 133070 entries, 0 to 133069\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   Date                133070 non-null  datetime64[ns]\n",
      " 1   Stock               133070 non-null  object        \n",
      " 2   DIVIDEND YIELD      133023 non-null  float64       \n",
      " 3   MARKET VALUE        133024 non-null  float64       \n",
      " 4   MRKT VALUE TO BOOK  131217 non-null  float64       \n",
      " 5   PER                 122217 non-null  float64       \n",
      " 6   PRICE INDEX         133024 non-null  float64       \n",
      " 7   TOT RETURN IND      133024 non-null  float64       \n",
      " 8   TURNOVER BY VALUE   123194 non-null  float64       \n",
      " 9   TURNOVER BY VOLUME  132989 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), object(1)\n",
      "memory usage: 11.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_panel = df_panel.sort_values([\"Stock\", \"Date\"])\n",
    "\n",
    "print(df_panel.head())\n",
    "print(df_panel.tail())\n",
    "print(df_panel.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "dbcecd1d-30e3-4aa6-b543-fefcd3fc199a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_panel[\"Stock\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9bbb3c-6757-4b83-97e9-1dd5ac7fa062",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb753e-eab8-473a-a358-5056d88befbf",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>1.2</small>&nbsp;&nbsp;&nbsp;&nbsp;Risk-Free:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "11529cc6-3a20-4373-a873-6f5c19966ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = pd.read_excel(path + \"EURIBOR.xlsx\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "10f74c61-52a1-47dd-9497-ac73dbdc86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df.columns = rf_df.iloc[0]\n",
    "rf_df = rf_df.iloc[1:].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "ec6023b0-32d3-41ee-878f-6168e7248571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATE', 'TIME PERIOD', 'OBS.VALUE'], dtype='object', name=0)"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_df.head()\n",
    "rf_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "7bc8a7c8-6e96-4ac6-be77-8de0bac996ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = rf_df.rename(columns={\n",
    "    \"DATE\": \"Date\",\n",
    "    \"OBS.VALUE\": \"Rf\"\n",
    "})\n",
    "rf_df = rf_df.drop(columns=[\"TIME PERIOD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "0863ab87-646c-4a1a-9f16-4523b6bd4a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df[\"Date\"] = pd.to_datetime(rf_df[\"Date\"])\n",
    "rf_df[\"Rf\"] = rf_df[\"Rf\"].astype(float) / 100 / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "89024896-2bea-4197-bfea-4e2875e12cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df[\"Date\"] = rf_df[\"Date\"] + pd.offsets.MonthBegin(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "10ddf115-bd8b-4c90-b2a1-c3f9467f2cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0         Date        Rf\n",
       "0   2005-01-01  0.001806\n",
       "1   2005-02-01  0.001759\n",
       "2   2005-03-01  0.001753\n",
       "3   2005-04-01  0.001753\n",
       "4   2005-05-01  0.001754\n",
       "..         ...       ...\n",
       "247 2025-08-01  0.001577\n",
       "248 2025-09-01  0.001575\n",
       "249 2025-10-01  0.001581\n",
       "250 2025-11-01  0.001589\n",
       "251 2025-12-01  0.001588\n",
       "\n",
       "[252 rows x 2 columns]>"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1592f41-7e17-4d6e-a52a-0df7fde7899f",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c85c2c-1a4f-4de9-bb6c-fa6219e53ce6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>1.3</small>&nbsp;&nbsp;&nbsp;&nbsp;Merging:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "d2dfadbf-9554-4c89-a47b-907cb170bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almost = df_panel.merge(\n",
    "    rf_df,\n",
    "    on=\"Date\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "4a14f4c4-000c-4d19-a0f8-670a670d9194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    133070.000000\n",
       "mean          0.000881\n",
       "std           0.001363\n",
       "min          -0.000497\n",
       "25%          -0.000308\n",
       "50%           0.000216\n",
       "75%           0.001866\n",
       "max           0.004026\n",
       "Name: Rf, dtype: float64"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_almost[\"Rf\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "ba19e0c5-a7b0-44f1-b75e-c6e987ed20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almost.to_csv(path + \"Data1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5415219-20a2-4beb-aec8-97ca9023bbe6",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:4px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ec6867-93c5-46ab-be21-6e46e2a63134",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h2> <small>2</small>&nbsp;&nbsp;&nbsp;&nbsp;Data Management:</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea065ca-2191-4276-9f12-21222229f120",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17194ef-f40e-4f5a-b19e-070296f5646b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>2.1</small>&nbsp;&nbsp;&nbsp;&nbsp;From Long to Panel</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "51669fcf-73b0-4d03-8c0b-c74ce76a771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_almost.columns.tolist()\n",
    "cols_no_date = [c for c in cols if c != \"Date\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "8c7d768c-2ed9-4f4f-ba8e-523446c19cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_almost.melt(\n",
    "    id_vars=[\"Date\", \"Stock\"],\n",
    "    var_name=\"Variable\",\n",
    "    value_name=\"value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "f5d07627-92aa-4dec-86e5-5f7443caa720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Stock', 'Variable', 'value'], dtype='object')"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "d9a38685-f690-4521-83f2-fe7bdf28b96e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>3I GROUP</td>\n",
       "      <td>DIVIDEND YIELD</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>3I GROUP</td>\n",
       "      <td>DIVIDEND YIELD</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-03-01</td>\n",
       "      <td>3I GROUP</td>\n",
       "      <td>DIVIDEND YIELD</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-04-01</td>\n",
       "      <td>3I GROUP</td>\n",
       "      <td>DIVIDEND YIELD</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-05-01</td>\n",
       "      <td>3I GROUP</td>\n",
       "      <td>DIVIDEND YIELD</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     Stock        Variable  value\n",
       "0 2005-01-01  3I GROUP  DIVIDEND YIELD   2.13\n",
       "1 2005-02-01  3I GROUP  DIVIDEND YIELD   2.00\n",
       "2 2005-03-01  3I GROUP  DIVIDEND YIELD   2.04\n",
       "3 2005-04-01  3I GROUP  DIVIDEND YIELD   2.11\n",
       "4 2005-05-01  3I GROUP  DIVIDEND YIELD   2.23"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long.columns\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "3c340733-dcfe-4cd9-a149-97700520b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel = (\n",
    "    df_long\n",
    "    .pivot_table(\n",
    "        index=[\"Date\", \"Stock\"],\n",
    "        columns=\"Variable\",\n",
    "        values=\"value\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365de6c8-8578-450f-941a-e850008b78cf",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200172e-01cd-4035-ab26-89c600fd2153",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>2.2.</small>&nbsp;&nbsp;&nbsp;&nbsp;Excess Returns:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "ec5f7fa8-3308-43be-a380-b334fcaf0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel[\"RET\"] = (\n",
    "    df_panel\n",
    "    .groupby(\"Stock\")[\"TOT RETURN IND\"]\n",
    "    .pct_change(fill_method=None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "6d2d432d-89d1-4b63-962e-5e62f1dd338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel[\"RET_FWD\"] = df_panel.groupby(\"Stock\")[\"RET\"].shift(-1)\n",
    "df_panel[\"EXCESS_RET_FWD\"] = df_panel[\"RET_FWD\"] - df_panel[\"Rf\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1a7f0-e00b-44ab-b706-ada20bea747b",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a577cc2-42c5-4d3a-b3c2-17bae2f6bc4d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>2.3</small>&nbsp;&nbsp;&nbsp;&nbsp;Firm Characteristics:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "7e00d962-4d6a-4584-a6ba-c9e14fbcc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_log(x):\n",
    "    out = np.full_like(x, np.nan, dtype=\"float64\")\n",
    "    mask = x > 0\n",
    "    out[mask] = np.log(x[mask])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "924e145f-8da1-4589-a698-8e2fd5a3963c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_panel[\"LOG_PRICE\"] = safe_log(df_panel[\"PRICE INDEX\"])\n",
    "df_panel[\"SIZE\"]      = safe_log(df_panel[\"MARKET VALUE\"])\n",
    "df_panel[\"BM\"]        = 1 / df_panel[\"MRKT VALUE TO BOOK\"]\n",
    "df_panel[\"DY\"]        = df_panel[\"DIVIDEND YIELD\"] / 100\n",
    "df_panel[\"EY\"]        = 1 / df_panel[\"PER\"]\n",
    "\n",
    "df_panel[\"TURN_VAL\"]  = safe_log(df_panel[\"TURNOVER BY VALUE\"])\n",
    "df_panel[\"TURN_VOL\"]  = safe_log(df_panel[\"TURNOVER BY VOLUME\"])\n",
    "\n",
    "df_panel[\"MOM3\"]  = (\n",
    "    df_panel.groupby(\"Stock\")[\"LOG_PRICE\"]\n",
    "            .transform(lambda s: s.shift(2) - s.shift(5))\n",
    ")\n",
    "\n",
    "df_panel[\"MOM12\"] = (\n",
    "    df_panel.groupby(\"Stock\")[\"LOG_PRICE\"]\n",
    "            .transform(lambda s: s.shift(2) - s.shift(13))\n",
    ")\n",
    "\n",
    "df_panel[\"VOL12\"] = (\n",
    "    df_panel.groupby(\"Stock\")[\"RET\"]\n",
    "            .rolling(12, min_periods=12)\n",
    "            .std()\n",
    "            .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "df_panel[\"VOL12\"] = df_panel.groupby(\"Stock\")[\"VOL12\"].shift(1)\n",
    "\n",
    "market_cols = [\"SIZE\",\"TURN_VAL\",\"TURN_VOL\",\"LOG_PRICE\"]\n",
    "df_panel[market_cols] = (\n",
    "    df_panel.groupby(\"Stock\")[market_cols].shift(1)\n",
    ")\n",
    "\n",
    "fund_cols = [\"BM\",\"DY\",\"EY\"]\n",
    "df_panel[fund_cols] = (\n",
    "    df_panel.groupby(\"Stock\")[fund_cols].shift(6)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf908a4-21f0-47b2-bf23-b699e5327a72",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd47b6-e1b3-4bbb-90ed-77684898292c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>2.4</small>&nbsp;&nbsp;&nbsp;&nbsp;Interaction Terms:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "08b83ff6-9498-4736-8e6e-1310fb88f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel[\"SIZE_BM\"]   = df_panel[\"SIZE\"] * df_panel[\"BM\"]\n",
    "df_panel[\"SIZE_MOM\"]  = df_panel[\"SIZE\"] * df_panel[\"MOM12\"]\n",
    "df_panel[\"SIZE_VOL\"]  = df_panel[\"SIZE\"] * df_panel[\"VOL12\"]\n",
    "df_panel[\"SIZE_LIQ\"]  = df_panel[\"SIZE\"] * df_panel[\"TURN_VAL\"]\n",
    "df_panel[\"BM_MOM\"] = df_panel[\"BM\"] * df_panel[\"MOM12\"]\n",
    "df_panel[\"BM_VOL\"] = df_panel[\"BM\"] * df_panel[\"VOL12\"]\n",
    "df_panel[\"BM_LIQ\"] = df_panel[\"BM\"] * df_panel[\"TURN_VAL\"]\n",
    "df_panel[\"MOM_VOL\"] = df_panel[\"MOM12\"] * df_panel[\"VOL12\"]\n",
    "df_panel[\"MOM_LIQ\"] = df_panel[\"MOM12\"] * df_panel[\"TURN_VAL\"]\n",
    "df_panel[\"MOM_PRICE\"] = df_panel[\"MOM12\"] * df_panel[\"LOG_PRICE\"]\n",
    "df_panel[\"EY_MOM\"] = df_panel[\"EY\"] * df_panel[\"MOM12\"]\n",
    "df_panel[\"DY_SIZE\"] = df_panel[\"DY\"] * df_panel[\"SIZE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed8b28-06bf-430e-8be4-20724dff801d",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aca272-6547-44a8-a478-40f6d37fa848",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>2.5</small>&nbsp;&nbsp;&nbsp;&nbsp;Standarization & Winsorization :</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "0e32d0c6-4e87-4451-9d51-de832a519c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics = [\n",
    "    \"SIZE\",\"BM\",\"DY\",\"EY\",\"MOM3\",\"MOM12\",\"VOL12\",\n",
    "    \"TURN_VAL\",\"TURN_VOL\",\"LOG_PRICE\"\n",
    "]\n",
    "\n",
    "interaction_terms = [\n",
    "    \"SIZE_BM\",\"SIZE_MOM\",\"SIZE_VOL\",\"SIZE_LIQ\",\n",
    "    \"BM_MOM\",\"BM_VOL\",\"BM_LIQ\",\n",
    "    \"MOM_VOL\",\"MOM_LIQ\",\"MOM_PRICE\",\n",
    "    \"EY_MOM\",\"DY_SIZE\"\n",
    "]\n",
    "\n",
    "predictors = characteristics + interaction_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "93cd41ab-f027-483d-aa05-505432a218a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable       Date                Stock  DIVIDEND YIELD  MARKET VALUE  \\\n",
      "0        2005-01-01             3I GROUP            2.13       4085.77   \n",
      "1        2005-01-01  A P MOLLER MAERSK B            0.66     100668.40   \n",
      "2        2005-01-01                  A2A            2.94       3060.08   \n",
      "3        2005-01-01             AALBERTS            1.54        878.29   \n",
      "4        2005-01-01            ABB LTD N            0.00      13477.75   \n",
      "\n",
      "Variable  MRKT VALUE TO BOOK   PER  PRICE INDEX        Rf  TOT RETURN IND  \\\n",
      "0                       1.12  30.4        244.9  0.001806          302.56   \n",
      "1                       1.75   9.1       5126.9  0.001806         6348.85   \n",
      "2                       1.86  15.7        199.7  0.001806          231.36   \n",
      "3                       2.94  20.4       1378.8  0.001806         1844.24   \n",
      "4                       2.93  10.4        292.8  0.001806          579.90   \n",
      "\n",
      "Variable  TURNOVER BY VALUE  ...  SIZE_VOL  SIZE_LIQ  BM_MOM  BM_VOL  BM_LIQ  \\\n",
      "0                  340749.3  ...       NaN       NaN     NaN     NaN     NaN   \n",
      "1                 4164371.0  ...       NaN       NaN     NaN     NaN     NaN   \n",
      "2                  190588.8  ...       NaN       NaN     NaN     NaN     NaN   \n",
      "3                   25559.0  ...       NaN       NaN     NaN     NaN     NaN   \n",
      "4                 2415166.0  ...       NaN       NaN     NaN     NaN     NaN   \n",
      "\n",
      "Variable  MOM_VOL  MOM_LIQ  MOM_PRICE  EY_MOM  DY_SIZE  \n",
      "0             NaN      NaN        NaN     NaN      NaN  \n",
      "1             NaN      NaN        NaN     NaN      NaN  \n",
      "2             NaN      NaN        NaN     NaN      NaN  \n",
      "3             NaN      NaN        NaN     NaN      NaN  \n",
      "4             NaN      NaN        NaN     NaN      NaN  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_panel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "1bed8f5e-b730-497c-9f0b-eeb1d5807d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 22 (10 characteristics and 12 interaction terms)\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(predictors)} ({len(characteristics)} characteristics and {len(interaction_terms)} interaction terms)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb607ea2-441a-4c7c-8518-2c33de9afbf1",
   "metadata": {},
   "source": [
    "But first, following the GKN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "8c67eb67-b8d9-419b-986c-44a2d41a6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSStandardizer:\n",
    "    def __init__(self, lower=0.01, upper=0.99):\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.q_low = None\n",
    "        self.q_high = None\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit(self, df, cols):\n",
    "        self.q_low  = df[cols].quantile(self.lower)\n",
    "        self.q_high = df[cols].quantile(self.upper)\n",
    "        self.mean   = df[cols].mean()\n",
    "        self.std    = df[cols].std()\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, cols):\n",
    "        x = df[cols].clip(self.q_low, self.q_high, axis=1)\n",
    "        z = (x - self.mean) / self.std\n",
    "\n",
    "        return z.fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "2930c428-4232-4fc0-9558-41caedf1b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FINAL= df_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "910a144a-b308-4de7-a8c9-b8aeb6183f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FINAL.to_csv(path + \"FINAL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af538c-bb05-4f13-bbe8-a583d5de0b17",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:4px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314429f-a8d8-4751-8eea-0504f136d3ed",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h2> <small>3</small>&nbsp;&nbsp;&nbsp;&nbsp;Splitting:</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de8a16-59fb-4b36-ba07-ee3abd3600bf",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304ad4e-888b-460f-810c-b8da341866c0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>3.1</small>&nbsp;&nbsp;&nbsp;&nbsp;Test-Train Splitting:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "937e40e8-b6c1-4f39-8c30-70b5feda9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FINAL[\"Date\"] = pd.to_datetime(df_FINAL[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "0a715415-f9fc-4e72-a435-12179e758b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-01-01 00:00:00 2018-12-01 00:00:00\n",
      "2019-01-01 00:00:00 2025-12-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train = df_FINAL[df_FINAL[\"Date\"] < \"2019-01-01\"].copy()\n",
    "test  = df_FINAL[df_FINAL[\"Date\"] >= \"2019-01-01\"].copy()\n",
    "\n",
    "print(train[\"Date\"].min(), train[\"Date\"].max())\n",
    "print(test[\"Date\"].min(), test[\"Date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "0aacbbe4-3127-4061-adcd-06dfcaca1996",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"EXCESS_RET_FWD\"]\n",
    "y_test  = test[\"EXCESS_RET_FWD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "8cc234dd-818f-41ca-881b-657c3236e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[predictors]\n",
    "X_test  = test[predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "73bfdf9e-0604-45b3-8045-0e8b02c98eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84217, 22), (84217,))"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085b120d-8592-4943-8002-526f867270a4",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589647a4-7ce6-44a6-a991-749d86d584ee",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>3.2</small>&nbsp;&nbsp;&nbsp;&nbsp; Exluding NaN for Returns & Imputation :</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "04c2a46c-7925-45ba-9331-c0ff62db7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=[\"EXCESS_RET_FWD\"])\n",
    "test  = test.dropna(subset=[\"EXCESS_RET_FWD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "095b38b6-acf1-4914-968c-2e0bc994631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs_median_impute(df, cols):\n",
    "    df[cols] = (\n",
    "        df\n",
    "        .groupby(\"Date\")[cols]\n",
    "        .transform(lambda x: x.fillna(x.median()))\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "5f398afa-eec8-4dd1-bc5e-408ee62b41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cs_median_impute(train, predictors)\n",
    "test  = cs_median_impute(test, predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "b4b6f8c0-603c-407b-be19-c02beed0c8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    155\n",
       "True      13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_by_date = (\n",
    "    train\n",
    "    .groupby(\"Date\")[predictors]\n",
    "    .apply(lambda x: x.isna().any().any())\n",
    ")\n",
    "\n",
    "missing_by_date.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "71c6af83-81b6-4826-bfa2-22d6bb742463",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dates = missing_by_date[~missing_by_date].index\n",
    "\n",
    "train = train[train[\"Date\"].isin(valid_dates)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "30dbf7cb-f1a9-4542-9208-5561201609ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[predictors].isna().sum().sum(), train[\"EXCESS_RET_FWD\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df9555-6e51-4187-9700-6404ec0dd638",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0457552-2775-463e-8bfd-10228312c8c4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>3.3</small>&nbsp;&nbsp;&nbsp;&nbsp; Rolling Window Cross-Validation:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "bd1857de-b4cd-4f94-a5ad-c59d93c20b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollingPanelSplit:\n",
    "    \"\"\"\n",
    "    Rolling time-based split for panel data (Date × Stock)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_months : int\n",
    "        Length of training window in months\n",
    "    val_months : int or None\n",
    "        Length of validation window in months (None = no validation)\n",
    "    test_months : int\n",
    "        Length of test window in months\n",
    "    step_months : int\n",
    "        Step size of the rolling window\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_months=120,\n",
    "                 val_months=None,\n",
    "                 test_months=12,\n",
    "                 step_months=12):\n",
    "\n",
    "        self.train_months = train_months\n",
    "        self.val_months = val_months\n",
    "        self.test_months = test_months\n",
    "        self.step_months = step_months\n",
    "\n",
    "    def split(self, df, date_col=\"Date\"):\n",
    "        \"\"\"\n",
    "        Returns a list of (train_idx, val_idx, test_idx)\n",
    "        \"\"\"\n",
    "\n",
    "        df = df.sort_values(date_col).copy()\n",
    "        dates = df[date_col].drop_duplicates().sort_values()\n",
    "\n",
    "        splits = []\n",
    "\n",
    "        start = dates.min() + relativedelta(months=self.train_months)\n",
    "\n",
    "        while True:\n",
    "            train_start = start - relativedelta(months=self.train_months)\n",
    "            train_end = start\n",
    "\n",
    "            if self.val_months is not None:\n",
    "                val_end = train_end + relativedelta(months=self.val_months)\n",
    "                test_end = val_end + relativedelta(months=self.test_months)\n",
    "            else:\n",
    "                val_end = None\n",
    "                test_end = train_end + relativedelta(months=self.test_months)\n",
    "\n",
    "            if test_end > dates.max():\n",
    "                break\n",
    "\n",
    "            train_idx = df[\n",
    "                (df[date_col] >= train_start) &\n",
    "                (df[date_col] < train_end)\n",
    "            ].index\n",
    "\n",
    "            if self.val_months is not None:\n",
    "                val_idx = df[\n",
    "                    (df[date_col] >= train_end) &\n",
    "                    (df[date_col] < val_end)\n",
    "                ].index\n",
    "            else:\n",
    "                val_idx = None\n",
    "\n",
    "            test_idx = df[\n",
    "                (df[date_col] >= (val_end if val_end else train_end)) &\n",
    "                (df[date_col] < test_end)\n",
    "            ].index\n",
    "\n",
    "            splits.append((train_idx, val_idx, test_idx))\n",
    "\n",
    "            start += relativedelta(months=self.step_months)\n",
    "\n",
    "        return splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b96e2-0955-45b6-911e-973c492a03e5",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:4px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633d2d11-dd0d-48ac-ad0d-89b76b1001cf",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h2> <small>4</small>&nbsp;&nbsp;&nbsp;&nbsp;Indicators Functions:</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c32a6-bf5e-48ca-a263-5c1df252291e",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed82f1-5766-4e88-b209-a7f18b53b0bd",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>4.1</small>&nbsp;&nbsp;&nbsp;&nbsp; $R^2_{OOS}$ &nbsp;Function:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "aa811b1d-faf1-4c63-9be3-7559112bfff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oos_r2(df, y_true=\"y_true\", y_pred=\"y_pred\", date_col=\"Date\"):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(date_col)\n",
    "\n",
    "    m = df.groupby(date_col)[y_true].mean()\n",
    "    m_hist = m.expanding().mean().shift(1)\n",
    "\n",
    "    df[\"mean_fc\"] = df[date_col].map(m_hist)\n",
    "\n",
    "    valid = (\n",
    "        df[\"mean_fc\"].notna()\n",
    "        & df[y_true].notna()\n",
    "        & df[y_pred].notna()\n",
    "    )\n",
    "\n",
    "    if valid.sum() == 0:\n",
    "        return np.nan\n",
    "\n",
    "    sse = ((df.loc[valid, y_true] - df.loc[valid, y_pred]) ** 2).sum()\n",
    "    sst = ((df.loc[valid, y_true] - df.loc[valid, \"mean_fc\"]) ** 2).sum()\n",
    "\n",
    "    if not np.isfinite(sst) or sst <= 0:\n",
    "        return np.nan\n",
    "\n",
    "    return 1 - sse / sst\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d4cce-6868-45f6-a490-edf2eceb159b",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a94e794-a587-4743-85ff-39f16b185ac2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>4.2</small>&nbsp;&nbsp;&nbsp;&nbsp; H-L Portifolio Function:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "c961761e-637e-4596-b917-90c3388a7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hl_month(df, q=0.1, pred_col=\"y_pred\", ret_col=\"y_true\"):\n",
    "    \"\"\"\n",
    "    High-Low portfolio return for one cross-section\n",
    "    \"\"\"\n",
    "    df = df[[pred_col, ret_col]].dropna()\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "\n",
    "    q_low = df[pred_col].quantile(q)\n",
    "    q_high = df[pred_col].quantile(1 - q)\n",
    "\n",
    "    return (\n",
    "        df.loc[df[pred_col] >= q_high, ret_col].mean()\n",
    "        - df.loc[df[pred_col] <= q_low, ret_col].mean()\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c940b8-9948-42f2-9fc1-2f57f8bae6d3",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6aa102-8304-42f1-a9be-0d0de8aa7b1f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>4.2</small>&nbsp;&nbsp;&nbsp;&nbsp; $Sharpe$ (H-L) Function:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "89f755a3-03a4-46a2-b602-ec37fb38543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe(returns, periods_per_year=12):\n",
    "    mean = returns.mean()\n",
    "    std  = returns.std()\n",
    "    return np.sqrt(periods_per_year) * mean / std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "0e641fb5-ad37-4da4-ba73-1785a22f4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_gkn(returns, oos_r2, periods_per_year=12):\n",
    "    SR = sharpe(returns, periods_per_year)\n",
    "    return np.sqrt((SR**2 + oos_r2) / (1 - oos_r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc50eba-7794-4adc-aebb-539c07a293e0",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:4px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98867078-949b-49b0-b3ec-da22d13d9494",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h2> <small>5</small>&nbsp;&nbsp;&nbsp;&nbsp;OLS:</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6cb093-fd4d-48cb-8dc0-835a3a08dec1",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd06bdf2-9150-409f-aac4-c2a6fd0a964f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>5.1</small>&nbsp;&nbsp;&nbsp;&nbsp; Function:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "27578d35-8106-4e93-b98d-3a781f3a65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RollingPanelSplit(\n",
    "    train_months=120,   \n",
    "    val_months=None,    \n",
    "    test_months=12,    \n",
    "    step_months=12      \n",
    ")\n",
    "splits = splitter.split(df_FINAL, date_col=\"Date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "4373ab7d-8485-4604-b3fe-2d3c5e975ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rolling_ols(df, splits, predictors, target):\n",
    "    \"\"\"\n",
    "    Rolling OLS with proper lagging and train-only standardization\n",
    "    \"\"\"\n",
    "    oos_results = []\n",
    "\n",
    "    for split_id, (train_idx, _, test_idx) in enumerate(splits):\n",
    "\n",
    "        train = df.loc[train_idx].copy()\n",
    "        test  = df.loc[test_idx].copy()\n",
    "\n",
    "        train = train.dropna(subset=predictors + [target])\n",
    "        test  = test.dropna(subset=predictors + [target])\n",
    "\n",
    "        if len(train) == 0 or len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        # ----------------------------\n",
    "        # Winsorazation\n",
    "        # ----------------------------\n",
    "        stdzr = CSStandardizer(lower=0.01, upper=0.99)\n",
    "        stdzr.fit(train, predictors)\n",
    "\n",
    "        X_train = stdzr.transform(train, predictors).values\n",
    "        X_test  = stdzr.transform(test, predictors).values\n",
    "\n",
    "        y_train = train[target].values\n",
    "        y_test  = test[target].values\n",
    "\n",
    "        # ----------------------------\n",
    "        # OLS FULL\n",
    "        # ----------------------------\n",
    "        model = LinearRegression(fit_intercept=True)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        out = test[[\"Date\", \"Stock\"]].copy()\n",
    "        out[\"y_true\"] = y_test\n",
    "        out[\"y_pred\"] = y_pred\n",
    "        out[\"model\"]  = \"OLS\"\n",
    "        out[\"split\"]  = split_id\n",
    "\n",
    "        oos_results.append(out)\n",
    "\n",
    "    return pd.concat(oos_results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "eb82af97-16d4-456b-b09c-1eda7d6fa4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"EXCESS_RET_FWD\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "d93be85d-1c25-4faf-a744-4157fada27e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_full = run_rolling_ols(\n",
    "    df=df_FINAL,\n",
    "    splits=splits,\n",
    "    predictors=predictors,\n",
    "    target=target\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "69b985b1-b6a5-4c83-963e-8a08b56895a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Stock', 'y_true', 'y_pred', 'model', 'split'], dtype='object', name='Variable')"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_full.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea2c67-9818-4f5f-94eb-6587585d362e",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4abfe72-49b8-4088-99fc-071a085e006d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>5.2</small>&nbsp;&nbsp;&nbsp;&nbsp; Results:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "e2b6340d-ea2b-4650-a2b8-328c5a4b3a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS R² (OLS): 0.0048\n"
     ]
    }
   ],
   "source": [
    "r2_ols = oos_r2(ols_full)\n",
    "print(f\"OOS R² (OLS): {r2_ols:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "ca279381-37fc-46ab-aaec-b3562e53ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_ols_full = (\n",
    "    ols_full\n",
    "    .groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "    .apply(hl_month)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "58eedd37-5c14-4652-885c-cab5e7a36510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHARPE (GKN) (OLS H–L): 1.12\n"
     ]
    }
   ],
   "source": [
    "sharpe_ols_full = sharpe_gkn(hl_ols_full, r2_ols,periods_per_year=12)\n",
    "\n",
    "print(f\"SHARPE (GKN) (OLS H–L): {sharpe_ols_full:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "f006dffc-a776-4f33-957c-a5cd5f6f5769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120.000000\n",
       "mean       0.007664\n",
       "std        0.001646\n",
       "min        0.003972\n",
       "25%        0.006698\n",
       "50%        0.007276\n",
       "75%        0.008463\n",
       "max        0.012552\n",
       "Name: y_pred, dtype: float64"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_full.groupby(\"Date\")[\"y_pred\"].std().describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf253ca-2cdb-41a5-980f-8ba7e5fe2ba8",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b64796-f5d0-4891-8eb1-f564f3fe9885",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>5.3</small>&nbsp;&nbsp;&nbsp;&nbsp; Look-Ahead-Bias Check:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "cdd68a48-87a0-46ca-84b8-e41d80b93517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placebo Sharpe: -0.043532761780642616\n"
     ]
    }
   ],
   "source": [
    "tmp = ols_full.copy()\n",
    "tmp[\"y_pred\"] = np.random.randn(len(tmp))\n",
    "\n",
    "hl_placebo = (\n",
    "    tmp.groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "       .apply(hl_month)\n",
    ")\n",
    "\n",
    "print(\"Placebo Sharpe:\", sharpe(hl_placebo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "93199a7e-ea40-4e72-9612-fee80ece7be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1.1168272126128513\n",
      "0.2 0.9001529565525419\n",
      "0.3 0.7472272294659577\n",
      "0.4 0.8442322784325166\n"
     ]
    }
   ],
   "source": [
    "for q in [0.1, 0.2, 0.3, 0.4]:\n",
    "    hl_q = (\n",
    "        ols_full.groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "               .apply(lambda m: hl_month(m, q=q))\n",
    "    )\n",
    "    print(q, sharpe(hl_q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "f25f504f-827d-436a-90c8-dcf28d1ed61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifted Sharpe: 1.1794348727452957\n"
     ]
    }
   ],
   "source": [
    "ols_test = ols_full.copy()\n",
    "ols_test[\"y_pred\"] = ols_test.groupby(\"Stock\")[\"y_pred\"].shift(1)\n",
    "\n",
    "hl_shifted = (\n",
    "    ols_test\n",
    "    .groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "    .apply(hl_month)\n",
    ")\n",
    "\n",
    "print(\"Shifted Sharpe:\", sharpe(hl_shifted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f660201e-4394-461a-a8ea-5b451f1a996a",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:4px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51040360-b4cf-43a9-b6af-23912ccb76a9",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h2> <small>6</small>&nbsp;&nbsp;&nbsp;&nbsp; OLS-3:</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320fa6f-3fea-4c8a-b050-99125987386c",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d9c2c-211a-44b7-b605-113688798335",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>6.1</small>&nbsp;&nbsp;&nbsp;&nbsp; Function:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "f506c292-aad6-4052-ae29-0f5acf57bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_3 = [\"SIZE\", \"BM\", \"MOM12\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "9d89123a-42b9-470e-b77a-495c3a6f6216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rolling_ols(df, splits, predictors, target):\n",
    "    \"\"\"\n",
    "    Rolling OLS-3 with proper lagging and train-only standardization\n",
    "    \"\"\"\n",
    "    oos_results = []\n",
    "\n",
    "    for split_id, (train_idx, _, test_idx) in enumerate(splits):\n",
    "\n",
    "        train = df.loc[train_idx].copy()\n",
    "        test  = df.loc[test_idx].copy()\n",
    "\n",
    "        train = train.dropna(subset=predictors + [target])\n",
    "        test  = test.dropna(subset=predictors + [target])\n",
    "\n",
    "        if len(train) == 0 or len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        # ----------------------------\n",
    "        # Winsorazation\n",
    "        # ----------------------------\n",
    "        stdzr = CSStandardizer(lower=0.01, upper=0.99)\n",
    "        stdzr.fit(train, predictors)\n",
    "\n",
    "        X_train = stdzr.transform(train, predictors).values\n",
    "        X_test  = stdzr.transform(test, predictors).values\n",
    "\n",
    "        y_train = train[target].values\n",
    "        y_test  = test[target].values\n",
    "\n",
    "        # ----------------------------\n",
    "        # OLS FULL\n",
    "        # ----------------------------\n",
    "        model = LinearRegression(fit_intercept=True)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        out = test[[\"Date\", \"Stock\"]].copy()\n",
    "        out[\"y_true\"] = y_test\n",
    "        out[\"y_pred\"] = y_pred\n",
    "        out[\"model\"]  = \"OLS\"\n",
    "        out[\"split\"]  = split_id\n",
    "\n",
    "        oos_results.append(out)\n",
    "\n",
    "    return pd.concat(oos_results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "a17f4da4-c446-43fa-846b-47d1091df2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"EXCESS_RET_FWD\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "a7e4ce0f-e429-4f64-9f68-c4787642a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_3 = run_rolling_ols(\n",
    "    df=df_FINAL,\n",
    "    splits=splits,\n",
    "    predictors=predictors_3,\n",
    "    target=target\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd3d280-4da9-47f3-a213-4f6dd05ac1ab",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d651d1-02d1-4dc7-a2a9-768495e3479e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>6.2</small>&nbsp;&nbsp;&nbsp;&nbsp; Results:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "d93b6729-039f-4858-ad31-7f6520b4aa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS R² (OLS): 0.0092\n"
     ]
    }
   ],
   "source": [
    "r2_ols3 = oos_r2(ols_3)\n",
    "print(f\"OOS R² (OLS): {r2_ols3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "26906652-637c-459a-b940-7dc7b262fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_ols_3 = (\n",
    "    ols_3\n",
    "    .groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "    .apply(hl_month)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "1b2f444e-a1ba-42a6-bb1c-a63038750ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHARPE (GKN) (OLS-3 H–L): 0.90\n"
     ]
    }
   ],
   "source": [
    "sharpe_ols_3= sharpe_gkn(hl_ols_3, r2_ols3,periods_per_year=12)\n",
    "\n",
    "print(f\"SHARPE (GKN) (OLS-3 H–L): {sharpe_ols_3:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d1482-2b06-4e75-b202-ef86b663a892",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134a872-8bd7-4a2f-b83c-2441ae40b109",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>6.3</small>&nbsp;&nbsp;&nbsp;&nbsp; Look-Ahead-Bias Check:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "90ba37cc-c30e-46c9-9e7b-b8175bbd510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placebo Sharpe: 0.060446359699921\n"
     ]
    }
   ],
   "source": [
    "tmp = ols_3.copy()\n",
    "tmp[\"y_pred\"] = np.random.randn(len(tmp))\n",
    "\n",
    "hl_placebo = (\n",
    "    tmp.groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "       .apply(hl_month)\n",
    ")\n",
    "\n",
    "print(\"Placebo Sharpe:\", sharpe(hl_placebo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "f951358a-c97b-4b51-8191-041cadc8d41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.8864557679789561\n",
      "0.2 0.8986452448108644\n",
      "0.3 0.7694268813201175\n",
      "0.4 0.7454840367813187\n"
     ]
    }
   ],
   "source": [
    "for q in [0.1, 0.2, 0.3, 0.4]:\n",
    "    hl_q = (\n",
    "        ols_3.groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "               .apply(lambda m: hl_month(m, q=q))\n",
    "    )\n",
    "    print(q, sharpe(hl_q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "f23cd85d-27fb-4172-a6f1-074ac56409ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifted Sharpe: 0.9460486557929799\n"
     ]
    }
   ],
   "source": [
    "ols_test = ols_3.copy()\n",
    "ols_test[\"y_pred\"] = ols_test.groupby(\"Stock\")[\"y_pred\"].shift(1)\n",
    "\n",
    "hl_shifted = (\n",
    "    ols_test\n",
    "    .groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "    .apply(hl_month)\n",
    ")\n",
    "\n",
    "print(\"Shifted Sharpe:\", sharpe(hl_shifted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3a05a-e30f-4acd-91c7-b739af4e569b",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:4px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69591481-1e90-4242-ab18-90e19a178764",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h2> <small>7</small>&nbsp;&nbsp;&nbsp;&nbsp; Elastic-Net:</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aca4b3-045d-41d2-ad26-823091963d6b",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28529982-e4c3-4882-aa6f-a8574b5bdad3",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>7.1</small>&nbsp;&nbsp;&nbsp;&nbsp; Function:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "85db121a-c98b-4bba-9d04-fea48b6f20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RollingPanelSplit(\n",
    "    train_months=120,\n",
    "    val_months=12,   \n",
    "    test_months=12,\n",
    "    step_months=12\n",
    ")\n",
    "\n",
    "splits = splitter.split(df_FINAL, date_col=\"Date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "d77fc971-d083-44c9-b68a-c52ecaa1ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_grid = np.logspace(-4, 1, 20)\n",
    "l1_ratio = 0.5  #FOR ELASTIC NET!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "2c74d72e-ebab-4b82-ae1e-94c3c04bf7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rolling_enet(df, splits, predictors, target, alpha_grid, l1_ratio=0.5):\n",
    "    oos_results = []\n",
    "\n",
    "    for split_id, (train_idx, val_idx, test_idx) in enumerate(splits):\n",
    "\n",
    "        # ----------------------------\n",
    "        # Split data\n",
    "        # ----------------------------\n",
    "        train = df.loc[train_idx].copy()\n",
    "        val   = df.loc[val_idx].copy()\n",
    "        test  = df.loc[test_idx].copy()\n",
    "\n",
    "        train = train.dropna(subset=predictors + [target])\n",
    "        val   = val.dropna(subset=predictors + [target])\n",
    "        test  = test.dropna(subset=predictors + [target])\n",
    "\n",
    "        if len(train) == 0 or len(val) == 0 or len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        # ----------------------------\n",
    "        # Standardization (TRAIN ONLY)\n",
    "        # ----------------------------\n",
    "        stdzr = CSStandardizer(lower=0.01, upper=0.99)\n",
    "        stdzr.fit(train, predictors)\n",
    "\n",
    "        X_train = stdzr.transform(train, predictors).values\n",
    "        y_train = train[target].values\n",
    "\n",
    "        X_val = stdzr.transform(val, predictors).values\n",
    "        y_val = val[target].values\n",
    "\n",
    "        X_test = stdzr.transform(test, predictors).values\n",
    "        y_test = test[target].values\n",
    "\n",
    "        # ----------------------------\n",
    "        # Hyperparameter tuning (TRAIN → VAL)\n",
    "        # ----------------------------\n",
    "        best_alpha = None\n",
    "        best_mse = np.inf\n",
    "\n",
    "        for alpha in alpha_grid:\n",
    "            model = ElasticNet(\n",
    "                alpha=alpha,\n",
    "                l1_ratio=l1_ratio,\n",
    "                fit_intercept=True,\n",
    "                max_iter=10_000\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            mse = np.mean((y_val - val_pred) ** 2)\n",
    "\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_alpha = alpha\n",
    "\n",
    "        # ----------------------------\n",
    "        # Refit on TRAIN ∪ VAL\n",
    "        # ----------------------------\n",
    "        X_tv = np.vstack([X_train, X_val])\n",
    "        y_tv = np.concatenate([y_train, y_val])\n",
    "\n",
    "        final_model = ElasticNet(\n",
    "            alpha=best_alpha,\n",
    "            l1_ratio=l1_ratio,\n",
    "            fit_intercept=True,\n",
    "            max_iter=10_000\n",
    "        )\n",
    "        final_model.fit(X_tv, y_tv)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Predict on TEST\n",
    "        # ----------------------------\n",
    "        y_pred = final_model.predict(X_test)\n",
    "\n",
    "        out = test[[\"Date\", \"Stock\"]].copy()\n",
    "        out[\"y_true\"] = y_test\n",
    "        out[\"y_pred\"] = y_pred\n",
    "        out[\"model\"]  = \"ElasticNet\"\n",
    "        out[\"alpha\"]  = best_alpha\n",
    "        out[\"split\"]  = split_id\n",
    "\n",
    "        oos_results.append(out)\n",
    "\n",
    "    return pd.concat(oos_results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "c8d5c5fa-3bda-4bde-9f09-4b6da31588a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_full = run_rolling_enet(\n",
    "    df=df_FINAL,\n",
    "    splits=splits,\n",
    "    predictors=predictors,\n",
    "    target=\"EXCESS_RET_FWD\",\n",
    "    alpha_grid=alpha_grid,\n",
    "    l1_ratio=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "9a9cf6d3-40c0-4150-a73e-f872b9b993c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    108.000000\n",
       "mean       0.002972\n",
       "std        0.002722\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.003572\n",
       "75%        0.004584\n",
       "max        0.008171\n",
       "Name: y_pred, dtype: float64"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_full[\"alpha\"].describe()\n",
    "enet_full.groupby(\"Date\")[\"y_pred\"].std().describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd057913-a1b8-4007-ad1d-7042d4bde24d",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea3e11-09a6-4328-a967-578971a461ac",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>7.2</small>&nbsp;&nbsp;&nbsp;&nbsp; Results:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "33832cb4-4e4f-4e57-8b65-6811bfbfff2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS R² (ENet): 0.0081\n"
     ]
    }
   ],
   "source": [
    "r2_enet = oos_r2(enet_full)\n",
    "print(f\"OOS R² (ENet): {r2_enet:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "30383895-aaf7-4f07-a9ef-cbb1a07905cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_enet = (\n",
    "    enet_full\n",
    "    .groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "    .apply(lambda m: hl_month(m, q=0.1))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "0f1e2209-03fe-4563-95ff-f2c23e2848e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHARPE (GKN) (OLS H–L): 0.59\n"
     ]
    }
   ],
   "source": [
    "sharpe_enet = sharpe_gkn(hl_enet, r2_enet,periods_per_year=12)\n",
    "\n",
    "print(f\"SHARPE (GKN) (OLS H–L): {sharpe_enet:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811ab90-0578-485b-afc1-2b2296093513",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b1b5a-5a9d-44b4-a9d6-bdf92867d908",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>7.3</small>&nbsp;&nbsp;&nbsp;&nbsp; Look-Ahead-Bias Check:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "f5ed63a2-9319-4e71-8e51-ca7f92d2256b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placebo Sharpe: 0.18694196221390422\n"
     ]
    }
   ],
   "source": [
    "tmp = enet_full.copy()\n",
    "tmp[\"y_pred\"] = np.random.randn(len(tmp))\n",
    "\n",
    "hl_placebo = (\n",
    "    tmp.groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "       .apply(hl_month)\n",
    ")\n",
    "\n",
    "print(\"Placebo Sharpe:\", sharpe(hl_placebo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "c8e55352-8312-4f17-a761-02b79b247584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.5791700351638633\n",
      "0.2 0.5405024661626145\n",
      "0.3 0.5136890940028711\n",
      "0.4 0.4462684789543502\n"
     ]
    }
   ],
   "source": [
    "for q in [0.1, 0.2, 0.3, 0.4]:\n",
    "    hl_q = (\n",
    "        enet_full.groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "               .apply(lambda m: hl_month(m, q=q))\n",
    "    )\n",
    "    print(q, sharpe(hl_q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "7183c3aa-2424-43a4-b09d-51d55444ea93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifted Sharpe: 0.7321861709725014\n"
     ]
    }
   ],
   "source": [
    "enet_test = enet_full.copy()\n",
    "enet_test[\"y_pred\"] = enet_test.groupby(\"Stock\")[\"y_pred\"].shift(1)\n",
    "\n",
    "hl_shifted = (\n",
    "    enet_test\n",
    "    .groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "    .apply(hl_month)\n",
    ")\n",
    "\n",
    "print(\"Shifted Sharpe:\", sharpe(hl_shifted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa1a75-5999-4dfe-9a6a-28a48ee91a93",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:4px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd01c11-3a21-45d5-a5ba-ddb72393fcc3",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h2> <small>8</small>&nbsp;&nbsp;&nbsp;&nbsp; Random Forest:</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b55fce0-57e2-4cd4-8fb0-5465806b3c7b",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e597b4a-edd0-4e78-8909-8956e57f7d9d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>8.1</small>&nbsp;&nbsp;&nbsp;&nbsp; Function:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "ac091805-40d6-4088-ad17-e1bb55d73c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RollingPanelSplit(\n",
    "    train_months=120,\n",
    "    val_months=12,\n",
    "    test_months=12,\n",
    "    step_months=12\n",
    ")\n",
    "\n",
    "splits = splitter.split(df_FINAL, date_col=\"Date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "33d4d3ef-c23a-40ad-bb35-884694f2b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = {\n",
    "    \"max_depth\": [1,2,3,4,5,6],\n",
    "    \"max_features\": [3, 6, 12, 24, 46, 49]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "id": "8c5fda9c-6c1c-403d-b033-881d83b3e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [2, 4, 6],\n",
    "    \"max_features\": [int(np.sqrt(len(predictors))), len(predictors)//3]\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(param_grid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "e701efb3-d123-44bc-9dd4-3b1b11404d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "id": "71d72c23-4e4b-4f6f-be17-6e04c63cd842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def run_rolling_rf_gkn_style(df, splits, predictors, target, grid, random_state=42):\n",
    "\n",
    "    predictions = []\n",
    "    y_test_list = []\n",
    "    dates = []\n",
    "    dic_r2_all = {}\n",
    "    dic_max_depth_all = {}\n",
    "\n",
    "    for split_id, (train_idx, val_idx, test_idx) in enumerate(splits):\n",
    "\n",
    "        # ----------------------------\n",
    "        # Split data\n",
    "        # ----------------------------\n",
    "        train = df.loc[train_idx].copy()\n",
    "        val   = df.loc[val_idx].copy()\n",
    "        test  = df.loc[test_idx].copy()\n",
    "\n",
    "        train = train.dropna(subset=predictors + [target])\n",
    "        val   = val.dropna(subset=predictors + [target])\n",
    "        test  = test.dropna(subset=predictors + [target])\n",
    "\n",
    "        if len(train) == 0 or len(val) == 0 or len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        # ----------------------------\n",
    "        # Standardization (TRAIN ONLY)\n",
    "        # ----------------------------\n",
    "        stdzr = CSStandardizer(lower=0.01, upper=0.99)\n",
    "        stdzr.fit(train, predictors)\n",
    "\n",
    "        X_train = stdzr.transform(train, predictors).values\n",
    "        y_train = train[target].values\n",
    "\n",
    "        X_val = stdzr.transform(val, predictors).values\n",
    "        y_val = val[target].values\n",
    "\n",
    "        X_test = stdzr.transform(test, predictors).values\n",
    "        y_test = test[target].values\n",
    "\n",
    "        # ----------------------------\n",
    "        # Hyperparameter tuning (TRAIN → VAL)\n",
    "        # ----------------------------\n",
    "        mse = np.full(len(grid), np.nan, dtype=np.float64)\n",
    "\n",
    "        for j, params in enumerate(grid):\n",
    "\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=params[\"max_depth\"],\n",
    "                max_features=params[\"max_features\"],\n",
    "                min_samples_leaf=40,\n",
    "                n_jobs=-1,\n",
    "                random_state=random_state\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            mse[j] = np.mean((y_val - val_pred) ** 2)\n",
    "\n",
    "        best_idx = np.argmin(mse)\n",
    "        best_params = grid[best_idx]\n",
    "\n",
    "        dic_max_depth_all[split_id] = best_params[\"max_depth\"]\n",
    "\n",
    "        # ----------------------------\n",
    "        # Refit on TRAIN ∪ VAL\n",
    "        # ----------------------------\n",
    "        X_tv = np.vstack([X_train, X_val])\n",
    "        y_tv = np.concatenate([y_train, y_val])\n",
    "\n",
    "        final_model = RandomForestRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=best_params[\"max_depth\"],\n",
    "            max_features=best_params[\"max_features\"],\n",
    "            min_samples_leaf=40,\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        final_model.fit(X_tv, y_tv)\n",
    "\n",
    "        y_pred = final_model.predict(X_test)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Store results\n",
    "        # ----------------------------\n",
    "        out = test[[\"Date\", \"Stock\"]].copy()\n",
    "        out[\"y_true\"] = y_test\n",
    "        out[\"y_pred\"] = y_pred\n",
    "        out[\"model\"]  = \"RF\"\n",
    "        out[\"split\"]  = split_id\n",
    "        out[\"max_depth\"] = best_params[\"max_depth\"]\n",
    "        out[\"max_features\"] = best_params[\"max_features\"]\n",
    "\n",
    "        predictions.append(out)\n",
    "\n",
    "    return pd.concat(predictions, ignore_index=True), dic_max_depth_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "181614fb-e30d-4007-8eb1-fc391d50d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf, rf_depths = run_rolling_rf_gkn_style(\n",
    "    df=df_FINAL,\n",
    "    splits=splits,\n",
    "    predictors=predictors,\n",
    "    target=\"EXCESS_RET_FWD\",\n",
    "    grid=grid\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "7c2f497c-fec4-44fe-89c7-30ba0661d48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS R² (RF): 0.0111\n"
     ]
    }
   ],
   "source": [
    "r2_rf = oos_r2(rf)\n",
    "print(f\"OOS R² (RF): {r2_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "57624786-1ac6-4619-a3b8-c64e4c7a74f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_rf = (\n",
    "    rf\n",
    "    .groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "    .apply(lambda m: hl_month(m, q=0.1))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "493db2da-8dbe-4b26-84ae-cd1f7bbe8060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHARPE (GKN) (RF): 0.74\n"
     ]
    }
   ],
   "source": [
    "sharpe_rf = sharpe_gkn(hl_rf, r2_rf,periods_per_year=12)\n",
    "\n",
    "print(f\"SHARPE (GKN) (RF): {sharpe_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4737aaa9-c5de-46eb-aca7-e520a385fbcb",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4244daa-e0f5-4277-a7bf-2646a1bcfef7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>7.3</small>&nbsp;&nbsp;&nbsp;&nbsp; Look-Ahead-Bias Check:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "9d6ad6e5-ffad-431a-a3cf-797e6295fbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placebo Sharpe: -0.25043149324891234\n"
     ]
    }
   ],
   "source": [
    "tmp = rf.copy()\n",
    "tmp[\"y_pred\"] = np.random.randn(len(tmp))\n",
    "\n",
    "hl_placebo = (\n",
    "    tmp.groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "       .apply(hl_month)\n",
    ")\n",
    "\n",
    "print(\"Placebo Sharpe:\", sharpe(hl_placebo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "11d13a8e-69a5-4c5b-a50b-c44a9d4036c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.7239904648122159\n",
      "0.2 0.7535808019926168\n",
      "0.3 0.6688057715824258\n",
      "0.4 0.6332876623711859\n"
     ]
    }
   ],
   "source": [
    "for q in [0.1, 0.2, 0.3, 0.4]:\n",
    "    hl_q = (\n",
    "        rf.groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "               .apply(lambda m: hl_month(m, q=q))\n",
    "    )\n",
    "    print(q, sharpe(hl_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "cc6730b3-c7bc-412a-aa8b-7697abd6279b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifted Sharpe: 0.9572485505286317\n"
     ]
    }
   ],
   "source": [
    "rf_test = rf.copy()\n",
    "rf_test[\"y_pred\"] = rf_test.groupby(\"Stock\")[\"y_pred\"].shift(1)\n",
    "\n",
    "hl_shifted = (\n",
    "    rf_test\n",
    "    .groupby(\"Date\")[[\"y_pred\", \"y_true\"]]\n",
    "    .apply(hl_month)\n",
    ")\n",
    "\n",
    "print(\"Shifted Sharpe:\", sharpe(hl_shifted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac407757-6abc-49a6-bbb1-c083736e7d5d",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:4px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc479d-004d-4015-8e40-9259af16ae45",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h2> <small>9</small>&nbsp;&nbsp;&nbsp;&nbsp; Neural Networks:</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c04fc-f57d-4d1f-80f8-f4a829e1436f",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be31e1-15d4-4fd0-9d0d-a33dcbe729dc",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h3> <small>9.1</small>&nbsp;&nbsp;&nbsp;&nbsp; Function:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "97f8a7f2-1bb4-4817-b9ff-e8c426db086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNN(tnn.Module):\n",
    "    def __init__(self, input_dim, hidden_units, depth):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers.append(tnn.Linear(input_dim, hidden_units))\n",
    "        layers.append(tnn.ReLU())\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(tnn.Linear(hidden_units, hidden_units))\n",
    "            layers.append(tnn.ReLU())\n",
    "\n",
    "        layers.append(tnn.Linear(hidden_units, 1))\n",
    "        self.net = tnn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "id": "a2666a2a-153d-4a43-b684-4fc9c84758bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X_train, y_train, X_val, y_val,\n",
    "             hidden_units, depth, l2,\n",
    "             epochs=50, lr=1e-3, batch_size=1024, seed=42):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    model = DeepNN(X_train.shape[1], hidden_units, depth)\n",
    "\n",
    "    optimizer = topt.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=l2\n",
    "    )\n",
    "\n",
    "    loss_fn = tnn.MSELoss()\n",
    "\n",
    "    X_tr = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_tr = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_va = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_va = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_tr)\n",
    "        loss = loss_fn(pred, y_tr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = model(X_va)\n",
    "        val_loss = loss_fn(val_pred, y_va).item()\n",
    "\n",
    "    return model, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "id": "fc965026-c5c8-4543-bed2-dbf475aa6c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_grid = [\n",
    "    {\"depth\": 3, \"hidden_units\": 32, \"l2\": 1e-4},\n",
    "    {\"depth\": 4, \"hidden_units\": 32, \"l2\": 1e-4},\n",
    "    {\"depth\": 5, \"hidden_units\": 32, \"l2\": 1e-4},\n",
    "    {\"depth\": 6, \"hidden_units\": 32, \"l2\": 1e-4},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "488172d7-edba-4cd0-9ab7-cde21418b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rolling_deep_nn(df, splits, predictors, target, nn_grid):\n",
    "\n",
    "    oos_results = []\n",
    "\n",
    "    for split_id, (train_idx, val_idx, test_idx) in enumerate(splits):\n",
    "\n",
    "        print(f\"NN split {split_id+1}/{len(splits)}\")\n",
    "\n",
    "        train = df.loc[train_idx].copy()\n",
    "        val   = df.loc[val_idx].copy()\n",
    "        test  = df.loc[test_idx].copy()\n",
    "\n",
    "        train = train.dropna(subset=predictors + [target])\n",
    "        val   = val.dropna(subset=predictors + [target])\n",
    "        test  = test.dropna(subset=predictors + [target])\n",
    "\n",
    "        if len(train) == 0 or len(val) == 0 or len(test) == 0:\n",
    "            continue\n",
    "\n",
    "        # ----------------------------\n",
    "        # Standardization (TRAIN ONLY)\n",
    "        # ----------------------------\n",
    "        stdzr = CSStandardizer(lower=0.01, upper=0.99)\n",
    "        stdzr.fit(train, predictors)\n",
    "\n",
    "        X_train = stdzr.transform(train, predictors).values\n",
    "        y_train = train[target].values\n",
    "\n",
    "        X_val = stdzr.transform(val, predictors).values\n",
    "        y_val = val[target].values\n",
    "\n",
    "        X_test = stdzr.transform(test, predictors).values\n",
    "        y_test = test[target].values\n",
    "\n",
    "        # ----------------------------\n",
    "        # Hyperparameter tuning\n",
    "        # ----------------------------\n",
    "        best_loss = np.inf\n",
    "        best_spec = None\n",
    "\n",
    "        for spec in nn_grid:\n",
    "            _, val_loss = train_nn(\n",
    "                X_train, y_train,\n",
    "                X_val, y_val,\n",
    "                hidden_units=spec[\"hidden_units\"],\n",
    "                depth=spec[\"depth\"],\n",
    "                l2=spec[\"l2\"]\n",
    "            )\n",
    "\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_spec = spec\n",
    "\n",
    "        # ----------------------------\n",
    "        # Refit on TRAIN ∪ VAL\n",
    "        # ----------------------------\n",
    "        X_tv = np.vstack([X_train, X_val])\n",
    "        y_tv = np.concatenate([y_train, y_val])\n",
    "\n",
    "        final_model, _ = train_nn(\n",
    "            X_tv, y_tv,\n",
    "            X_val, y_val,  # dummy\n",
    "            hidden_units=best_spec[\"hidden_units\"],\n",
    "            depth=best_spec[\"depth\"],\n",
    "            l2=best_spec[\"l2\"]\n",
    "        )\n",
    "\n",
    "        # ----------------------------\n",
    "        # Predict on TEST\n",
    "        # ----------------------------\n",
    "        final_model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = final_model(\n",
    "                torch.tensor(X_test, dtype=torch.float32)\n",
    "            ).numpy()\n",
    "\n",
    "        out = test[[\"Date\", \"Stock\"]].copy()\n",
    "        out[\"y_true\"] = y_test\n",
    "        out[\"y_pred\"] = y_pred\n",
    "        out[\"model\"]  = f\"NN{best_spec['depth']}\"\n",
    "        out[\"depth\"]  = best_spec[\"depth\"]\n",
    "        out[\"split\"]  = split_id\n",
    "\n",
    "        oos_results.append(out)\n",
    "\n",
    "    return pd.concat(oos_results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "816565c6-551e-41c0-bf60-6de9ec696e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN split 1/9\n",
      "NN split 2/9\n",
      "NN split 3/9\n",
      "NN split 4/9\n",
      "NN split 5/9\n",
      "NN split 6/9\n",
      "NN split 7/9\n",
      "NN split 8/9\n",
      "NN split 9/9\n"
     ]
    }
   ],
   "source": [
    "nn_deep = run_rolling_deep_nn(\n",
    "    df=df_FINAL,\n",
    "    splits=splits,\n",
    "    predictors=predictors,\n",
    "    target=\"EXCESS_RET_FWD\",\n",
    "    nn_grid=nn_grid\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "17676875-56ec-4867-95d8-ee6177bf666e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN3:  OOS R²=0.0328,  Sharpe=1.05,  GKN Sharpe=1.08\n",
      "NN4:  OOS R²=0.0579,  Sharpe=1.81,  GKN Sharpe=1.88\n",
      "NN5:  OOS R²=0.0093,  Sharpe=0.63,  GKN Sharpe=0.64\n",
      "NN6:  OOS R²=0.0904,  Sharpe=0.50,  GKN Sharpe=0.61\n"
     ]
    }
   ],
   "source": [
    "for d in [3,4,5,6]:\n",
    "    tmp = nn_deep[nn_deep[\"depth\"] == d]\n",
    "\n",
    "    r2 = oos_r2(tmp)\n",
    "    hl = (\n",
    "        tmp.groupby(\"Date\")[[\"y_pred\",\"y_true\"]]\n",
    "           .apply(lambda m: hl_month(m, q=0.1))\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"NN{d}:  OOS R²={r2:.4f},  \"\n",
    "        f\"Sharpe={sharpe(hl):.2f},  \"\n",
    "        f\"GKN Sharpe={sharpe_gkn(hl, r2):.2f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddb0d49-6f28-4728-8795-361b9924db21",
   "metadata": {},
   "source": [
    "<hr style=\"border:none;height:4px;background:#fff;margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae36633-1c72-47be-9c73-dcc7d1c510e4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: align;\">\n",
    "  <h2> <small>10</small>&nbsp;&nbsp;&nbsp;&nbsp; OLS+PCA:</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191fee6f-ef70-4c9c-850f-9cd9e5689353",
   "metadata": {},
   "source": [
    "<hr style=\"border:none; border-top:2px dashed #fff; margin:1em 0;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "75bc80e3-9cb2-4f7f-b7ef-9b268815f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rolling_ols3_pcr(\n",
    "    df,\n",
    "    splits,\n",
    "    predictors_3,\n",
    "    target,\n",
    "    K_grid=(0,1,2,3,4,5,6),\n",
    "    date_col=\"Date\",\n",
    "    stock_col=\"Stock\"\n",
    "):\n",
    "    \"\"\"\n",
    "    OLS-3 + Residual PCA (PCR-style), with LOCAL cleaning only.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for split_id, (train_idx, val_idx, test_idx) in enumerate(splits):\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 1) Extract data\n",
    "        # --------------------------------------------------\n",
    "        train = df.loc[train_idx].copy()\n",
    "        val   = df.loc[val_idx].copy()\n",
    "        test  = df.loc[test_idx].copy()\n",
    "\n",
    "        train = train.dropna(subset=predictors_3 + [target])\n",
    "        val   = val.dropna(subset=predictors_3 + [target])\n",
    "        test  = test.dropna(subset=predictors_3 + [target])\n",
    "\n",
    "        if len(train)==0 or len(val)==0 or len(test)==0:\n",
    "            continue\n",
    "\n",
    "        Xtr = train[predictors_3].values\n",
    "        ytr = train[target].values\n",
    "        Xva = val[predictors_3].values\n",
    "        yva = val[target].values\n",
    "        Xte = test[predictors_3].values\n",
    "        yte = test[target].values\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 2) LOCAL FIX: remove inf / NaN (OLS-PCR ONLY)\n",
    "        # --------------------------------------------------\n",
    "        Xtr = np.where(np.isfinite(Xtr), Xtr, np.nan)\n",
    "        Xva = np.where(np.isfinite(Xva), Xva, np.nan)\n",
    "        Xte = np.where(np.isfinite(Xte), Xte, np.nan)\n",
    "\n",
    "        mask_tr = ~np.isnan(Xtr).any(axis=1)\n",
    "        mask_va = ~np.isnan(Xva).any(axis=1)\n",
    "        mask_te = ~np.isnan(Xte).any(axis=1)\n",
    "\n",
    "        Xtr, ytr = Xtr[mask_tr], ytr[mask_tr]\n",
    "        Xva, yva = Xva[mask_va], yva[mask_va]\n",
    "        Xte, yte = Xte[mask_te], yte[mask_te]\n",
    "\n",
    "        train = train.iloc[mask_tr]\n",
    "        val   = val.iloc[mask_va]\n",
    "        test  = test.iloc[mask_te]\n",
    "\n",
    "        if len(train)==0 or len(val)==0 or len(test)==0:\n",
    "            continue\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 3) First-stage OLS-3\n",
    "        # --------------------------------------------------\n",
    "        ols3 = LinearRegression(fit_intercept=True)\n",
    "        ols3.fit(Xtr, ytr)\n",
    "\n",
    "        train[\"yhat_ols3\"] = ols3.predict(Xtr)\n",
    "        val[\"yhat_ols3\"]   = ols3.predict(Xva)\n",
    "        test[\"yhat_ols3\"]  = ols3.predict(Xte)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 4) Build TRAIN residual matrix\n",
    "        # --------------------------------------------------\n",
    "        train[\"resid\"] = train[target] - train[\"yhat_ols3\"]\n",
    "\n",
    "        E = (\n",
    "            train\n",
    "            .pivot(index=date_col, columns=stock_col, values=\"resid\")\n",
    "            .dropna(axis=1)\n",
    "        )\n",
    "\n",
    "        # Cross-sectional demeaning (standard)\n",
    "        E = E.sub(E.mean(axis=1), axis=0)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 5) Choose number of PCs on VALIDATION\n",
    "        # --------------------------------------------------\n",
    "        best_K = 0\n",
    "        best_mse = np.inf\n",
    "\n",
    "        for K in K_grid:\n",
    "\n",
    "            if K == 0 or E.shape[1] < K:\n",
    "                Ztr = train[[\"yhat_ols3\"]].values\n",
    "                Zva = val[[\"yhat_ols3\"]].values\n",
    "                ytr2, yva2 = ytr, yva\n",
    "\n",
    "            else:\n",
    "                pca = PCA(n_components=K)\n",
    "                pca.fit(E.values)\n",
    "\n",
    "                loadings = pd.DataFrame(\n",
    "                    pca.components_.T,\n",
    "                    index=E.columns,\n",
    "                    columns=[f\"pc{i+1}\" for i in range(K)]\n",
    "                )\n",
    "\n",
    "                train2 = train.merge(loadings, left_on=stock_col, right_index=True)\n",
    "                val2   = val.merge(loadings, left_on=stock_col, right_index=True)\n",
    "\n",
    "                if len(train2)==0 or len(val2)==0:\n",
    "                    continue\n",
    "\n",
    "                Ztr = train2[[\"yhat_ols3\"] + list(loadings.columns)].values\n",
    "                Zva = val2[[\"yhat_ols3\"] + list(loadings.columns)].values\n",
    "                ytr2 = train2[target].values\n",
    "                yva2 = val2[target].values\n",
    "\n",
    "            stage2 = LinearRegression()\n",
    "            stage2.fit(Ztr, ytr2)\n",
    "            mse = np.mean((yva2 - stage2.predict(Zva))**2)\n",
    "\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_K = K\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 6) Refit on TRAIN+VAL, predict TEST\n",
    "        # --------------------------------------------------\n",
    "        tv = pd.concat([train, val], axis=0)\n",
    "\n",
    "        if best_K == 0 or E.shape[1] < best_K:\n",
    "            Ztv = tv[[\"yhat_ols3\"]].values\n",
    "            stage2.fit(Ztv, tv[target].values)\n",
    "            y_pred = stage2.predict(test[[\"yhat_ols3\"]].values)\n",
    "\n",
    "        else:\n",
    "            pca = PCA(n_components=best_K)\n",
    "            pca.fit(E.values)\n",
    "\n",
    "            loadings = pd.DataFrame(\n",
    "                pca.components_.T,\n",
    "                index=E.columns,\n",
    "                columns=[f\"pc{i+1}\" for i in range(best_K)]\n",
    "            )\n",
    "\n",
    "            tv = tv.merge(loadings, left_on=stock_col, right_index=True)\n",
    "            test = test.merge(loadings, left_on=stock_col, right_index=True)\n",
    "\n",
    "            Ztv = tv[[\"yhat_ols3\"] + list(loadings.columns)].values\n",
    "            stage2.fit(Ztv, tv[target].values)\n",
    "\n",
    "            Zte = test[[\"yhat_ols3\"] + list(loadings.columns)].values\n",
    "            y_pred = stage2.predict(Zte)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 7) Store results\n",
    "        # --------------------------------------------------\n",
    "        out = test[[date_col, stock_col]].copy()\n",
    "        out[\"y_true\"] = test[target].values\n",
    "        out[\"y_pred\"] = y_pred\n",
    "        out[\"model\"]  = \"OLS3+PCR\"\n",
    "        out[\"K\"]      = best_K\n",
    "        out[\"split\"]  = split_id\n",
    "\n",
    "        results.append(out)\n",
    "\n",
    "    return pd.concat(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "id": "1a886b14-28d1-4feb-95d4-18a481e5aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pca = run_rolling_ols3_pcr(\n",
    "    df=df_FINAL,\n",
    "    splits=splits,\n",
    "    predictors_3=[\"SIZE\",\"BM\",\"MOM12\"],\n",
    "    target=\"EXCESS_RET_FWD\",\n",
    "    K_grid=[0,1,2]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "id": "b4e68a29-5311-427b-92bf-4f5548690085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K\n",
       "2    32206\n",
       "1    11142\n",
       "0     6711\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1021,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_pca[\"K\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "id": "a43be647-1c1a-4cc9-96b7-b9c0c2797f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013178352517500325\n",
      "Sharpe (GKN): 0.28562257453848666\n"
     ]
    }
   ],
   "source": [
    "r2_pcr = oos_r2(res_pca)\n",
    "hl_pcr = res_pca.groupby(\"Date\")[[\"y_pred\",\"y_true\"]].apply(lambda m: hl_month(m, q=0.1))\n",
    "print(r2_pcr)\n",
    "print(\"Sharpe (GKN):\", sharpe_gkn(hl_pcr, r2_pcr))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
